{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "from time import time\n",
    "\n",
    "from math import ceil\n",
    "from scipy.stats import spearmanr, gamma, poisson\n",
    "\n",
    "from anndata import AnnData, read_h5ad\n",
    "import scanpy as sc\n",
    "from scanpy import read\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import tensor\n",
    "from torch.cuda import is_available\n",
    "\n",
    "from sciPENN.sciPENN_API import sciPENN_API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for GPU\n",
      "GPU detected, using GPU\n",
      "\n",
      "QC Filtering Training Cells\n",
      "QC Filtering Testing Cells\n",
      "\n",
      "QC Filtering Training Genes\n",
      "QC Filtering Testing Genes\n",
      "\n",
      "Normalizing Training Cells\n",
      "Normalizing Testing Cells\n",
      "\n",
      "Log-Normalizing Training Data\n",
      "Log-Normalizing Testing Data\n",
      "\n",
      "Finding HVGs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'orig.ident' as categorical\n",
      "... storing 'lane' as categorical\n",
      "... storing 'donor' as categorical\n",
      "... storing 'time' as categorical\n",
      "... storing 'celltype.l1' as categorical\n",
      "... storing 'celltype.l2' as categorical\n",
      "... storing 'celltype.l3' as categorical\n",
      "... storing 'Phase' as categorical\n",
      "... storing 'batch' as categorical\n",
      "... storing 'Dataset' as categorical\n",
      "... storing 'barcode_check' as categorical\n",
      "... storing 'tenx_lane' as categorical\n",
      "... storing 'cohort' as categorical\n",
      "... storing 'hash_maxID' as categorical\n",
      "... storing 'hash_secondID' as categorical\n",
      "... storing 'hto_classification' as categorical\n",
      "... storing 'hto_classification_global' as categorical\n",
      "... storing 'hash_ID' as categorical\n",
      "... storing 'adjmfc.time' as categorical\n",
      "... storing 'DMX_GLOBAL_BEST' as categorical\n",
      "... storing 'DEMUXLET.BARCODE' as categorical\n",
      "... storing 'sample' as categorical\n",
      "... storing 'joint_classification_global' as categorical\n",
      "... storing 'timepoint' as categorical\n",
      "... storing 'K0' as categorical\n",
      "... storing 'K1' as categorical\n",
      "... storing 'K2' as categorical\n",
      "... storing 'K3' as categorical\n",
      "/home/jlakkis/miniconda3/envs/scipen/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing Gene Training Data by Batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing Protein Training Data by Batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:02<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing Gene Testing Data by Batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 17.34it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Read in Raw Data\"\"\"\n",
    "\n",
    "adata_gene = sc.read(\"../Data/pbmc/pbmc_gene.h5ad\")\n",
    "adata_protein = sc.read(\"../Data/pbmc/pbmc_protein.h5ad\")\n",
    "\n",
    "adata_gene_test = sc.read(\"../Data/H1N1/gene_data.mtx\").T\n",
    "adata_gene_test.var.index = pd.read_csv(\"../Data/H1N1/gene_names.txt\", index_col = 0).iloc[:, 0]\n",
    "adata_gene_test.obs = pd.read_csv(\"../Data/H1N1/meta_data.txt\", sep = ',', index_col = 0)\n",
    "\n",
    "sciPENN = sciPENN_API([adata_gene], [adata_protein], adata_gene_test, \n",
    "                    train_batchkeys = ['donor'], test_batchkey = 'sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_protein_test = sc.read(\"../Data/H1N1/protein_data.mtx\").T\n",
    "adata_protein_test.var.index = [x[:len(x) - 5] for x in pd.read_csv(\"../Data/H1N1/protein_names.txt\", index_col = 0).iloc[:,0]]\n",
    "adata_protein_test.obs = pd.read_csv(\"../Data/H1N1/meta_data.txt\", sep = ',', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 prediction loss = 1.398\n",
      "Epoch 1 prediction loss = 0.886\n",
      "Epoch 2 prediction loss = 0.880\n",
      "Epoch 3 prediction loss = 0.877\n",
      "Epoch 4 prediction loss = 0.874\n",
      "Epoch 5 prediction loss = 0.873\n",
      "Epoch 6 prediction loss = 0.873\n",
      "Epoch 7 prediction loss = 0.871\n",
      "Epoch 8 prediction loss = 0.870\n",
      "Epoch 9 prediction loss = 0.870\n",
      "Epoch 10 prediction loss = 0.869\n",
      "Epoch 11 prediction loss = 0.870\n",
      "Epoch 12 prediction loss = 0.867\n",
      "Epoch 13 prediction loss = 0.868\n",
      "Decaying loss to 0.0001\n",
      "Epoch 14 prediction loss = 0.858\n",
      "Epoch 15 prediction loss = 0.857\n",
      "Epoch 16 prediction loss = 0.857\n",
      "Epoch 17 prediction loss = 0.856\n",
      "Epoch 18 prediction loss = 0.857\n",
      "Epoch 19 prediction loss = 0.857\n",
      "Decaying loss to 1e-05\n",
      "Epoch 20 prediction loss = 0.856\n",
      "Epoch 21 prediction loss = 0.856\n",
      "Epoch 22 prediction loss = 0.856\n",
      "Epoch 23 prediction loss = 0.856\n",
      "Epoch 24 prediction loss = 0.856\n",
      "Epoch 25 prediction loss = 0.855\n",
      "Decaying loss to 1.0000000000000002e-06\n",
      "Epoch 26 prediction loss = 0.856\n"
     ]
    }
   ],
   "source": [
    "sciPENN.train(n_epochs = 10000, ES_max = 12, decay_max = 6, \n",
    "             decay_step = 0.1, lr = 10**(-3), weights_dir = \"weights_dir/pbmc_to_h1n1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_test = sciPENN.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'orig.ident' as categorical\n",
      "... storing 'batch' as categorical\n"
     ]
    }
   ],
   "source": [
    "embedding = sciPENN.embed()\n",
    "embedding.write(\"scipenn_pbmctoh1n1embedding.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlakkis/miniconda3/envs/scipen/lib/python3.7/site-packages/scanpy/preprocessing/_normalization.py:138: UserWarning: Revieved a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n",
      "/home/jlakkis/miniconda3/envs/scipen/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py:810: UserWarning: Revieved a view of an AnnData. Making a copy.\n",
      "  view_to_actual(adata)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Get test data\"\"\"\n",
    "\n",
    "adata_protein_test = sc.read(\"../Data/H1N1/protein_data.mtx\").T\n",
    "adata_protein_test.var.index = [x[:len(x) - 5] for x in pd.read_csv(\"../Data/H1N1/protein_names.txt\", index_col = 0).iloc[:,0]]\n",
    "adata_protein_test.obs = pd.read_csv(\"../Data/H1N1/meta_data.txt\", sep = ',', index_col = 0)\n",
    "\n",
    "adata_protein_test.X = adata_protein_test.X.toarray()\n",
    "adata_protein_test.layers[\"raw\"] = adata_protein_test.X\n",
    "\n",
    "adata_protein_test = adata_protein_test[imputed_test.obs.index]\n",
    "\n",
    "sc.pp.normalize_total(adata_protein_test)\n",
    "sc.pp.log1p(adata_protein_test)\n",
    "\n",
    "common_proteins = np.intersect1d(imputed_test.var.index, adata_protein_test.var.index)\n",
    "\n",
    "adata_protein_test = adata_protein_test[:, common_proteins]\n",
    "adata_protein_test.layers['imputed'] = imputed_test[:, common_proteins].X\n",
    "adata_protein_test.layers.update(imputed_test[:, common_proteins].layers)\n",
    "\n",
    "patients = np.unique(adata_protein_test.obs['sample'].values)\n",
    "\n",
    "for patient in patients:\n",
    "    indices = [x == patient for x in adata_protein_test.obs['sample']]\n",
    "    sub_adata = adata_protein_test[indices]\n",
    "\n",
    "    sc.pp.scale(sub_adata)\n",
    "    adata_protein_test[indices] = sub_adata.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2_coeff(A, B, pearson = True):\n",
    "    if pearson:\n",
    "        # Rowwise mean of input arrays & subtract from input arrays themeselves\n",
    "        A_mA = A - A.mean(1)[:, None]\n",
    "        B_mB = B - B.mean(1)[:, None]\n",
    "\n",
    "        # Sum of squares across rows\n",
    "        ssA = (A_mA**2).sum(1)\n",
    "        ssB = (B_mB**2).sum(1)\n",
    "\n",
    "        # Finally get corr coeff\n",
    "        corr_mat = np.dot(A_mA, B_mB.T) / np.sqrt(np.dot(ssA[:, None],ssB[None]))\n",
    "        \n",
    "        return corr_mat[range(corr_mat.shape[0]), range(corr_mat.shape[0])]\n",
    "    \n",
    "    else:\n",
    "        corrs = [0.] * A.shape[0]\n",
    "        \n",
    "        for i in range(A.shape[0]):\n",
    "            corrs[i] = spearmanr(A[i], B[i])[0]\n",
    "            \n",
    "        return corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Compute correlation across patients\"\"\"\n",
    "\n",
    "corrs = corr2_coeff(adata_protein_test.layers[\"imputed\"].T, adata_protein_test.X.T)\n",
    "corrs = pd.DataFrame(corrs)\n",
    "corrs.index = adata_protein_test.var.index\n",
    "corrs = corrs.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSEs= ((adata_protein_test.X - adata_protein_test.layers[\"imputed\"])**2).mean(axis = 0)**(1/2)\n",
    "\n",
    "protein_table = pd.DataFrame(np.concatenate((corrs.to_numpy(), np.expand_dims(MSEs, axis = 1), adata_protein_test.layers[\"raw\"].mean(axis = 0, keepdims = True).T), axis = 1), \n",
    "                             index = corrs.index, columns = [\"Correlations\", \"RMSE\", \"Mean Expression\"])\n",
    "\n",
    "protein_table[\"Log-Mean Expression\"] = np.log(protein_table[\"Mean Expression\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq = lambda x, y: (x - y)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Compute correlations within patient\"\"\"\n",
    "\n",
    "corrs_table = np.zeros((adata_protein_test.shape[1], len(np.unique(adata_protein_test.obs[\"sample\"]))))\n",
    "sq_table = corrs_table.copy()\n",
    "\n",
    "i = 0\n",
    "for patient in np.unique(adata_protein_test.obs[\"sample\"]):\n",
    "    truth = adata_protein_test[adata_protein_test.obs[\"sample\"] == patient].X.copy()\n",
    "    imputed = adata_protein_test.layers[\"imputed\"][adata_protein_test.obs[\"sample\"] == patient].copy()\n",
    "\n",
    "    corrs_table[:, i] = corr2_coeff(truth.T, imputed.T)\n",
    "    sq_table[:, i] = sq(truth, imputed).mean(axis = 0)\n",
    "    i += 1\n",
    "\n",
    "if np.isnan(corrs_table).sum() > 0:\n",
    "    corrs_table[np.isnan(corrs_table)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_table = pd.DataFrame(corrs_table)\n",
    "corrs_table.index, corrs_table.columns = adata_protein_test.var.index, np.unique(adata_protein_test.obs[\"sample\"])\n",
    "\n",
    "sq_table = pd.DataFrame(sq_table)\n",
    "sq_table.index, sq_table.columns = adata_protein_test.var.index, np.unique(adata_protein_test.obs[\"sample\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200_d0    0.551671\n",
       "201_d0    0.522775\n",
       "205_d0    0.523219\n",
       "207_d0    0.513245\n",
       "209_d0    0.534473\n",
       "212_d0    0.523326\n",
       "215_d0    0.544069\n",
       "229_d0    0.507505\n",
       "233_d0    0.507746\n",
       "234_d0    0.552363\n",
       "236_d0    0.507167\n",
       "237_d0    0.518251\n",
       "245_d0    0.520775\n",
       "250_d0    0.520766\n",
       "256_d0    0.556987\n",
       "261_d0    0.518480\n",
       "268_d0    0.517075\n",
       "273_d0    0.483878\n",
       "277_d0    0.533272\n",
       "279_d0    0.523227\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs_table.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52401347896025"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs_table.mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs_table.to_csv('corrs_results/scipenn_pbmctoh1n1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200_d0    0.639866\n",
       "201_d0    0.677758\n",
       "205_d0    0.670409\n",
       "207_d0    0.675455\n",
       "209_d0    0.639448\n",
       "212_d0    0.645429\n",
       "215_d0    0.642354\n",
       "229_d0    0.677762\n",
       "233_d0    0.679205\n",
       "234_d0    0.612601\n",
       "236_d0    0.691243\n",
       "237_d0    0.683056\n",
       "245_d0    0.678042\n",
       "250_d0    0.661990\n",
       "256_d0    0.620139\n",
       "261_d0    0.671863\n",
       "268_d0    0.663950\n",
       "273_d0    0.719429\n",
       "277_d0    0.649014\n",
       "279_d0    0.669926\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq_table.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6634469570371054"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sq_table.mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq_table.to_csv('mse_results/scipenn_pbmctoh1n1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective Coverage Probability for Nominal 50% PI: 0.473\n"
     ]
    }
   ],
   "source": [
    "r95 = (adata_protein_test.X < adata_protein_test.layers['q75'])\n",
    "l95 = (adata_protein_test.X > adata_protein_test.layers['q25'])\n",
    "\n",
    "print(f\"Effective Coverage Probability for Nominal 50% PI: {(r95*l95).mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective Coverage Probability for Nominal 80% PI: 0.776\n"
     ]
    }
   ],
   "source": [
    "r95 = (adata_protein_test.X < adata_protein_test.layers['q90'])\n",
    "l95 = (adata_protein_test.X > adata_protein_test.layers['q10'])\n",
    "\n",
    "print(f\"Effective Coverage Probability for Nominal 80% PI: {(r95*l95).mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'orig.ident' as categorical\n",
      "... storing 'tenx_lane' as categorical\n",
      "... storing 'cohort' as categorical\n",
      "... storing 'hash_maxID' as categorical\n",
      "... storing 'hash_secondID' as categorical\n",
      "... storing 'hto_classification' as categorical\n",
      "... storing 'hto_classification_global' as categorical\n",
      "... storing 'hash_ID' as categorical\n",
      "... storing 'adjmfc.time' as categorical\n",
      "... storing 'DMX_GLOBAL_BEST' as categorical\n",
      "... storing 'DEMUXLET.BARCODE' as categorical\n",
      "... storing 'sample' as categorical\n",
      "... storing 'joint_classification_global' as categorical\n",
      "... storing 'timepoint' as categorical\n",
      "... storing 'K0' as categorical\n",
      "... storing 'K1' as categorical\n",
      "... storing 'K2' as categorical\n",
      "... storing 'K3' as categorical\n"
     ]
    }
   ],
   "source": [
    "adata_protein_test.write(\"scipenn_pbmctoh1n1features.h5ad\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“scipen”",
   "language": "python",
   "name": "scipen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
