{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "from time import time\n",
    "\n",
    "from math import ceil\n",
    "from scipy.stats import spearmanr, gamma, poisson\n",
    "\n",
    "from anndata import AnnData, read_h5ad\n",
    "import scanpy as sc\n",
    "from scanpy import read\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import tensor\n",
    "from torch.cuda import is_available\n",
    "\n",
    "from sciPENN.sciPENN_API import sciPENN_API\n",
    "\n",
    "from os.path import join\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Read in Raw Data\"\"\"\n",
    "\n",
    "adata_gene = sc.read(\"../Data/pbmc/pbmc_gene.h5ad\")\n",
    "adata_protein = sc.read(\"../Data/pbmc/pbmc_protein.h5ad\")\n",
    "\n",
    "adata_gene_test = sc.read(\"../Data/H1N1/gene_data.mtx\").T\n",
    "adata_gene_test.var.index = pd.read_csv(\"../Data/H1N1/gene_names.txt\", index_col = 0).iloc[:, 0]\n",
    "adata_gene_test.obs = pd.read_csv(\"../Data/H1N1/meta_data.txt\", sep = ',', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"runtime\"\n",
    "train_path, test_path = join(base, 'train'), join(base, 'test')\n",
    "\n",
    "if not os.path.isdir(base):\n",
    "    os.mkdir(base)\n",
    "    os.mkdir(train_path), os.mkdir(test_path)\n",
    "    \n",
    "    indices = {frac: [] for frac in [0.1, 0.2, 0.4, 0.5, 0.8, 1.0]}\n",
    "    indices_test = {}\n",
    "    \n",
    "    np.random.seed(342)\n",
    "    n, n_test = len(adata_gene), len(adata_gene_test)\n",
    "    \n",
    "    for frac in indices:\n",
    "        indices[frac] = np.random.choice(range(n), round(frac * n), False).tolist()\n",
    "        pd.DataFrame(indices[frac], columns = ['idx']).to_csv(join(train_path, f\"idx{frac}.csv\"))\n",
    "        \n",
    "        indices_test[frac] = np.random.choice(range(n_test), round(frac * n_test), False).tolist()\n",
    "        pd.DataFrame(indices_test[frac], columns = ['idx']).to_csv(join(test_path, f\"idx{frac}.csv\"))\n",
    "\n",
    "else:\n",
    "    indices, indices_test = {}, {}\n",
    "    for path in os.listdir(train_path):\n",
    "        indices[float(path[3:6])] = pd.read_csv(join(train_path, path))['idx'].tolist()\n",
    "        indices_test[float(path[3:6])] = pd.read_csv(join(test_path, path))['idx'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to set attribute `.obs` of view, copying.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for GPU\n",
      "GPU detected, using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to set attribute `.obs` of view, copying.\n",
      "Trying to set attribute `.obs` of view, copying.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QC Filtering Training Cells\n",
      "QC Filtering Testing Cells\n",
      "\n",
      "QC Filtering Training Genes\n",
      "QC Filtering Testing Genes\n",
      "\n",
      "Normalizing Training Cells\n",
      "Normalizing Testing Cells\n",
      "\n",
      "Log-Normalizing Training Data\n",
      "Log-Normalizing Testing Data\n",
      "\n",
      "Finding HVGs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'orig.ident' as categorical\n",
      "... storing 'lane' as categorical\n",
      "... storing 'donor' as categorical\n",
      "... storing 'time' as categorical\n",
      "... storing 'celltype.l1' as categorical\n",
      "... storing 'celltype.l2' as categorical\n",
      "... storing 'celltype.l3' as categorical\n",
      "... storing 'Phase' as categorical\n",
      "... storing 'batch' as categorical\n",
      "... storing 'Dataset' as categorical\n",
      "... storing 'barcode_check' as categorical\n",
      "... storing 'tenx_lane' as categorical\n",
      "... storing 'cohort' as categorical\n",
      "... storing 'hash_maxID' as categorical\n",
      "... storing 'hash_secondID' as categorical\n",
      "... storing 'hto_classification' as categorical\n",
      "... storing 'hto_classification_global' as categorical\n",
      "... storing 'hash_ID' as categorical\n",
      "... storing 'adjmfc.time' as categorical\n",
      "... storing 'DMX_GLOBAL_BEST' as categorical\n",
      "... storing 'DEMUXLET.BARCODE' as categorical\n",
      "... storing 'sample' as categorical\n",
      "... storing 'joint_classification_global' as categorical\n",
      "... storing 'timepoint' as categorical\n",
      "... storing 'K0' as categorical\n",
      "... storing 'K1' as categorical\n",
      "... storing 'K2' as categorical\n",
      "... storing 'K3' as categorical\n",
      "/home/jlakkis/miniconda3/envs/scipen/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing Gene Training Data by Batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 12.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing Protein Training Data by Batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 17.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing Gene Testing Data by Batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 83.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 prediction loss = 1.397\n",
      "Epoch 1 prediction loss = 0.926\n",
      "Epoch 2 prediction loss = 0.915\n",
      "Epoch 3 prediction loss = 0.905\n",
      "Epoch 4 prediction loss = 0.905\n",
      "Epoch 5 prediction loss = 0.900\n",
      "Epoch 6 prediction loss = 0.899\n",
      "Epoch 7 prediction loss = 0.896\n",
      "Epoch 8 prediction loss = 0.895\n",
      "Epoch 9 prediction loss = 0.891\n",
      "Epoch 10 prediction loss = 0.891\n",
      "Epoch 11 prediction loss = 0.893\n",
      "Epoch 12 prediction loss = 0.891\n",
      "Epoch 13 prediction loss = 0.893\n",
      "Decaying loss to 0.0001\n",
      "Epoch 14 prediction loss = 0.878\n",
      "Epoch 15 prediction loss = 0.878\n",
      "Epoch 16 prediction loss = 0.877\n",
      "Epoch 17 prediction loss = 0.877\n",
      "Epoch 18 prediction loss = 0.878\n",
      "Epoch 19 prediction loss = 0.877\n",
      "Decaying loss to 1e-05\n",
      "Epoch 20 prediction loss = 0.876\n",
      "Epoch 21 prediction loss = 0.876\n",
      "Epoch 22 prediction loss = 0.876\n",
      "Epoch 23 prediction loss = 0.876\n",
      "Epoch 24 prediction loss = 0.876\n",
      "Epoch 25 prediction loss = 0.876\n",
      "Decaying loss to 1.0000000000000002e-06\n",
      "Epoch 26 prediction loss = 0.876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to set attribute `.obs` of view, copying.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for GPU\n",
      "GPU detected, using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to set attribute `.obs` of view, copying.\n",
      "Trying to set attribute `.obs` of view, copying.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QC Filtering Training Cells\n",
      "QC Filtering Testing Cells\n",
      "\n",
      "QC Filtering Training Genes\n",
      "QC Filtering Testing Genes\n",
      "\n",
      "Normalizing Training Cells\n",
      "Normalizing Testing Cells\n",
      "\n",
      "Log-Normalizing Training Data\n",
      "Log-Normalizing Testing Data\n",
      "\n",
      "Finding HVGs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'orig.ident' as categorical\n",
      "... storing 'lane' as categorical\n",
      "... storing 'donor' as categorical\n",
      "... storing 'time' as categorical\n",
      "... storing 'celltype.l1' as categorical\n",
      "... storing 'celltype.l2' as categorical\n",
      "... storing 'celltype.l3' as categorical\n",
      "... storing 'Phase' as categorical\n",
      "... storing 'batch' as categorical\n",
      "... storing 'Dataset' as categorical\n",
      "... storing 'barcode_check' as categorical\n",
      "... storing 'tenx_lane' as categorical\n",
      "... storing 'cohort' as categorical\n",
      "... storing 'hash_maxID' as categorical\n",
      "... storing 'hash_secondID' as categorical\n",
      "... storing 'hto_classification' as categorical\n",
      "... storing 'hto_classification_global' as categorical\n",
      "... storing 'hash_ID' as categorical\n",
      "... storing 'adjmfc.time' as categorical\n",
      "... storing 'DMX_GLOBAL_BEST' as categorical\n",
      "... storing 'DEMUXLET.BARCODE' as categorical\n",
      "... storing 'sample' as categorical\n",
      "... storing 'joint_classification_global' as categorical\n",
      "... storing 'timepoint' as categorical\n",
      "... storing 'K0' as categorical\n",
      "... storing 'K1' as categorical\n",
      "... storing 'K2' as categorical\n",
      "... storing 'K3' as categorical\n",
      "/home/jlakkis/miniconda3/envs/scipen/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing Gene Training Data by Batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing Protein Training Data by Batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 11.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing Gene Testing Data by Batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 74.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 prediction loss = 1.408\n",
      "Epoch 1 prediction loss = 0.918\n",
      "Epoch 2 prediction loss = 0.905\n",
      "Epoch 3 prediction loss = 0.897\n",
      "Epoch 4 prediction loss = 0.894\n",
      "Epoch 5 prediction loss = 0.891\n",
      "Epoch 6 prediction loss = 0.888\n",
      "Epoch 7 prediction loss = 0.887\n",
      "Epoch 8 prediction loss = 0.884\n",
      "Epoch 9 prediction loss = 0.884\n",
      "Epoch 10 prediction loss = 0.882\n",
      "Epoch 11 prediction loss = 0.880\n",
      "Epoch 12 prediction loss = 0.884\n",
      "Epoch 13 prediction loss = 0.880\n",
      "Decaying loss to 0.0001\n",
      "Epoch 14 prediction loss = 0.867\n",
      "Epoch 15 prediction loss = 0.867\n",
      "Epoch 16 prediction loss = 0.866\n",
      "Epoch 17 prediction loss = 0.866\n",
      "Epoch 18 prediction loss = 0.866\n",
      "Epoch 19 prediction loss = 0.866\n",
      "Decaying loss to 1e-05\n",
      "Epoch 20 prediction loss = 0.865\n",
      "Epoch 21 prediction loss = 0.865\n",
      "Epoch 22 prediction loss = 0.864\n",
      "Epoch 23 prediction loss = 0.865\n",
      "Epoch 24 prediction loss = 0.865\n",
      "Epoch 25 prediction loss = 0.865\n",
      "Decaying loss to 1.0000000000000002e-06\n",
      "Epoch 26 prediction loss = 0.865\n",
      "Searching for GPU\n",
      "GPU detected, using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to set attribute `.obs` of view, copying.\n",
      "Trying to set attribute `.obs` of view, copying.\n",
      "Trying to set attribute `.obs` of view, copying.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QC Filtering Training Cells\n",
      "QC Filtering Testing Cells\n",
      "\n",
      "QC Filtering Training Genes\n",
      "QC Filtering Testing Genes\n",
      "\n",
      "Normalizing Training Cells\n",
      "Normalizing Testing Cells\n",
      "\n",
      "Log-Normalizing Training Data\n",
      "Log-Normalizing Testing Data\n",
      "\n",
      "Finding HVGs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'orig.ident' as categorical\n",
      "... storing 'lane' as categorical\n",
      "... storing 'donor' as categorical\n",
      "... storing 'time' as categorical\n",
      "... storing 'celltype.l1' as categorical\n",
      "... storing 'celltype.l2' as categorical\n",
      "... storing 'celltype.l3' as categorical\n",
      "... storing 'Phase' as categorical\n",
      "... storing 'batch' as categorical\n",
      "... storing 'Dataset' as categorical\n",
      "... storing 'barcode_check' as categorical\n",
      "... storing 'tenx_lane' as categorical\n",
      "... storing 'cohort' as categorical\n",
      "... storing 'hash_maxID' as categorical\n",
      "... storing 'hash_secondID' as categorical\n",
      "... storing 'hto_classification' as categorical\n",
      "... storing 'hto_classification_global' as categorical\n",
      "... storing 'hash_ID' as categorical\n",
      "... storing 'adjmfc.time' as categorical\n",
      "... storing 'DMX_GLOBAL_BEST' as categorical\n",
      "... storing 'DEMUXLET.BARCODE' as categorical\n",
      "... storing 'sample' as categorical\n",
      "... storing 'joint_classification_global' as categorical\n",
      "... storing 'timepoint' as categorical\n",
      "... storing 'K0' as categorical\n",
      "... storing 'K1' as categorical\n",
      "... storing 'K2' as categorical\n",
      "... storing 'K3' as categorical\n",
      "/home/jlakkis/miniconda3/envs/scipen/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing Gene Training Data by Batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:02<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing Protein Training Data by Batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  7.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing Gene Testing Data by Batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 37.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 prediction loss = 1.388\n",
      "Epoch 1 prediction loss = 0.895\n",
      "Epoch 2 prediction loss = 0.886\n",
      "Epoch 3 prediction loss = 0.880\n",
      "Epoch 4 prediction loss = 0.876\n",
      "Epoch 5 prediction loss = 0.872\n",
      "Epoch 6 prediction loss = 0.870\n",
      "Epoch 7 prediction loss = 0.870\n",
      "Epoch 8 prediction loss = 0.866\n",
      "Epoch 9 prediction loss = 0.866\n",
      "Epoch 10 prediction loss = 0.868\n",
      "Epoch 11 prediction loss = 0.865\n",
      "Epoch 12 prediction loss = 0.862\n",
      "Epoch 13 prediction loss = 0.864\n",
      "Decaying loss to 0.0001\n",
      "Epoch 14 prediction loss = 0.852\n",
      "Epoch 15 prediction loss = 0.852\n",
      "Epoch 16 prediction loss = 0.851\n",
      "Epoch 17 prediction loss = 0.850\n",
      "Epoch 18 prediction loss = 0.850\n",
      "Epoch 19 prediction loss = 0.850\n",
      "Decaying loss to 1e-05\n",
      "Epoch 20 prediction loss = 0.850\n",
      "Epoch 21 prediction loss = 0.849\n",
      "Epoch 22 prediction loss = 0.848\n",
      "Epoch 23 prediction loss = 0.849\n",
      "Epoch 24 prediction loss = 0.849\n",
      "Epoch 25 prediction loss = 0.849\n",
      "Decaying loss to 1.0000000000000002e-06\n",
      "Epoch 26 prediction loss = 0.849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to set attribute `.obs` of view, copying.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for GPU\n",
      "GPU detected, using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to set attribute `.obs` of view, copying.\n",
      "Trying to set attribute `.obs` of view, copying.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QC Filtering Training Cells\n",
      "QC Filtering Testing Cells\n",
      "\n",
      "QC Filtering Training Genes\n",
      "QC Filtering Testing Genes\n",
      "\n",
      "Normalizing Training Cells\n",
      "Normalizing Testing Cells\n",
      "\n",
      "Log-Normalizing Training Data\n",
      "Log-Normalizing Testing Data\n",
      "\n",
      "Finding HVGs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'orig.ident' as categorical\n",
      "... storing 'lane' as categorical\n",
      "... storing 'donor' as categorical\n",
      "... storing 'time' as categorical\n",
      "... storing 'celltype.l1' as categorical\n",
      "... storing 'celltype.l2' as categorical\n",
      "... storing 'celltype.l3' as categorical\n",
      "... storing 'Phase' as categorical\n",
      "... storing 'batch' as categorical\n",
      "... storing 'Dataset' as categorical\n",
      "... storing 'barcode_check' as categorical\n",
      "... storing 'tenx_lane' as categorical\n",
      "... storing 'cohort' as categorical\n",
      "... storing 'hash_maxID' as categorical\n",
      "... storing 'hash_secondID' as categorical\n",
      "... storing 'hto_classification' as categorical\n",
      "... storing 'hto_classification_global' as categorical\n",
      "... storing 'hash_ID' as categorical\n",
      "... storing 'adjmfc.time' as categorical\n",
      "... storing 'DMX_GLOBAL_BEST' as categorical\n",
      "... storing 'DEMUXLET.BARCODE' as categorical\n",
      "... storing 'sample' as categorical\n",
      "... storing 'joint_classification_global' as categorical\n",
      "... storing 'timepoint' as categorical\n",
      "... storing 'K0' as categorical\n",
      "... storing 'K1' as categorical\n",
      "... storing 'K2' as categorical\n",
      "... storing 'K3' as categorical\n",
      "/home/jlakkis/miniconda3/envs/scipen/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing Gene Training Data by Batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:02<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing Protein Training Data by Batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:01<00:00,  5.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing Gene Testing Data by Batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 30.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 prediction loss = 1.390\n",
      "Epoch 1 prediction loss = 0.897\n",
      "Epoch 2 prediction loss = 0.885\n",
      "Epoch 3 prediction loss = 0.880\n",
      "Epoch 4 prediction loss = 0.875\n",
      "Epoch 5 prediction loss = 0.873\n",
      "Epoch 6 prediction loss = 0.871\n",
      "Epoch 7 prediction loss = 0.869\n",
      "Epoch 8 prediction loss = 0.868\n",
      "Epoch 9 prediction loss = 0.866\n",
      "Epoch 10 prediction loss = 0.867\n",
      "Epoch 11 prediction loss = 0.866\n",
      "Epoch 12 prediction loss = 0.866\n",
      "Decaying loss to 0.0001\n",
      "Epoch 13 prediction loss = 0.855\n",
      "Epoch 14 prediction loss = 0.855\n",
      "Epoch 15 prediction loss = 0.854\n",
      "Epoch 16 prediction loss = 0.854\n",
      "Epoch 17 prediction loss = 0.854\n",
      "Epoch 18 prediction loss = 0.854\n",
      "Decaying loss to 1e-05\n",
      "Epoch 19 prediction loss = 0.853\n",
      "Epoch 20 prediction loss = 0.853\n",
      "Epoch 21 prediction loss = 0.853\n",
      "Epoch 22 prediction loss = 0.853\n",
      "Epoch 23 prediction loss = 0.853\n",
      "Epoch 24 prediction loss = 0.853\n",
      "Decaying loss to 1.0000000000000002e-06\n",
      "Epoch 25 prediction loss = 0.853\n",
      "Searching for GPU\n",
      "GPU detected, using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to set attribute `.obs` of view, copying.\n",
      "Trying to set attribute `.obs` of view, copying.\n",
      "Trying to set attribute `.obs` of view, copying.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QC Filtering Training Cells\n",
      "QC Filtering Testing Cells\n",
      "\n",
      "QC Filtering Training Genes\n",
      "QC Filtering Testing Genes\n",
      "\n",
      "Normalizing Training Cells\n",
      "Normalizing Testing Cells\n",
      "\n",
      "Log-Normalizing Training Data\n",
      "Log-Normalizing Testing Data\n",
      "\n",
      "Finding HVGs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'orig.ident' as categorical\n",
      "... storing 'lane' as categorical\n",
      "... storing 'donor' as categorical\n",
      "... storing 'time' as categorical\n",
      "... storing 'celltype.l1' as categorical\n",
      "... storing 'celltype.l2' as categorical\n",
      "... storing 'celltype.l3' as categorical\n",
      "... storing 'Phase' as categorical\n",
      "... storing 'batch' as categorical\n",
      "... storing 'Dataset' as categorical\n",
      "... storing 'barcode_check' as categorical\n",
      "... storing 'tenx_lane' as categorical\n",
      "... storing 'cohort' as categorical\n",
      "... storing 'hash_maxID' as categorical\n",
      "... storing 'hash_secondID' as categorical\n",
      "... storing 'hto_classification' as categorical\n",
      "... storing 'hto_classification_global' as categorical\n",
      "... storing 'hash_ID' as categorical\n",
      "... storing 'adjmfc.time' as categorical\n",
      "... storing 'DMX_GLOBAL_BEST' as categorical\n",
      "... storing 'DEMUXLET.BARCODE' as categorical\n",
      "... storing 'sample' as categorical\n",
      "... storing 'joint_classification_global' as categorical\n",
      "... storing 'timepoint' as categorical\n",
      "... storing 'K0' as categorical\n",
      "... storing 'K1' as categorical\n",
      "... storing 'K2' as categorical\n",
      "... storing 'K3' as categorical\n",
      "/home/jlakkis/miniconda3/envs/scipen/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing Gene Training Data by Batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing Protein Training Data by Batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:02<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing Gene Testing Data by Batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 29.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 prediction loss = 1.396\n",
      "Epoch 1 prediction loss = 0.891\n",
      "Epoch 2 prediction loss = 0.881\n",
      "Epoch 3 prediction loss = 0.877\n",
      "Epoch 4 prediction loss = 0.875\n",
      "Epoch 5 prediction loss = 0.871\n",
      "Epoch 6 prediction loss = 0.871\n",
      "Epoch 7 prediction loss = 0.870\n",
      "Epoch 8 prediction loss = 0.867\n",
      "Epoch 9 prediction loss = 0.869\n",
      "Epoch 10 prediction loss = 0.870\n",
      "Epoch 11 prediction loss = 0.866\n",
      "Epoch 12 prediction loss = 0.866\n",
      "Epoch 13 prediction loss = 0.867\n",
      "Epoch 14 prediction loss = 0.867\n",
      "Epoch 15 prediction loss = 0.867\n",
      "Epoch 16 prediction loss = 0.865\n",
      "Decaying loss to 0.0001\n",
      "Epoch 17 prediction loss = 0.857\n",
      "Epoch 18 prediction loss = 0.856\n",
      "Epoch 19 prediction loss = 0.856\n",
      "Epoch 20 prediction loss = 0.856\n",
      "Epoch 21 prediction loss = 0.855\n",
      "Epoch 22 prediction loss = 0.855\n",
      "Decaying loss to 1e-05\n",
      "Epoch 23 prediction loss = 0.854\n",
      "Epoch 24 prediction loss = 0.855\n",
      "Epoch 25 prediction loss = 0.855\n",
      "Epoch 26 prediction loss = 0.854\n",
      "Epoch 27 prediction loss = 0.855\n",
      "Epoch 28 prediction loss = 0.854\n",
      "Decaying loss to 1.0000000000000002e-06\n",
      "Epoch 29 prediction loss = 0.854\n",
      "Searching for GPU\n",
      "GPU detected, using GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to set attribute `.obs` of view, copying.\n",
      "Trying to set attribute `.obs` of view, copying.\n",
      "Trying to set attribute `.obs` of view, copying.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QC Filtering Training Cells\n",
      "QC Filtering Testing Cells\n",
      "\n",
      "QC Filtering Training Genes\n",
      "QC Filtering Testing Genes\n",
      "\n",
      "Normalizing Training Cells\n",
      "Normalizing Testing Cells\n",
      "\n",
      "Log-Normalizing Training Data\n",
      "Log-Normalizing Testing Data\n",
      "\n",
      "Finding HVGs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'orig.ident' as categorical\n",
      "... storing 'lane' as categorical\n",
      "... storing 'donor' as categorical\n",
      "... storing 'time' as categorical\n",
      "... storing 'celltype.l1' as categorical\n",
      "... storing 'celltype.l2' as categorical\n",
      "... storing 'celltype.l3' as categorical\n",
      "... storing 'Phase' as categorical\n",
      "... storing 'batch' as categorical\n",
      "... storing 'Dataset' as categorical\n",
      "... storing 'barcode_check' as categorical\n",
      "... storing 'tenx_lane' as categorical\n",
      "... storing 'cohort' as categorical\n",
      "... storing 'hash_maxID' as categorical\n",
      "... storing 'hash_secondID' as categorical\n",
      "... storing 'hto_classification' as categorical\n",
      "... storing 'hto_classification_global' as categorical\n",
      "... storing 'hash_ID' as categorical\n",
      "... storing 'adjmfc.time' as categorical\n",
      "... storing 'DMX_GLOBAL_BEST' as categorical\n",
      "... storing 'DEMUXLET.BARCODE' as categorical\n",
      "... storing 'sample' as categorical\n",
      "... storing 'joint_classification_global' as categorical\n",
      "... storing 'timepoint' as categorical\n",
      "... storing 'K0' as categorical\n",
      "... storing 'K1' as categorical\n",
      "... storing 'K2' as categorical\n",
      "... storing 'K3' as categorical\n",
      "/home/jlakkis/miniconda3/envs/scipen/lib/python3.7/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing Gene Training Data by Batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing Protein Training Data by Batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:02<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Normalizing Gene Testing Data by Batch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 18.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 prediction loss = 1.392\n",
      "Epoch 1 prediction loss = 0.887\n",
      "Epoch 2 prediction loss = 0.879\n",
      "Epoch 3 prediction loss = 0.873\n",
      "Epoch 4 prediction loss = 0.871\n",
      "Epoch 5 prediction loss = 0.867\n",
      "Epoch 6 prediction loss = 0.867\n",
      "Epoch 7 prediction loss = 0.866\n",
      "Epoch 8 prediction loss = 0.866\n",
      "Epoch 9 prediction loss = 0.865\n",
      "Epoch 10 prediction loss = 0.864\n",
      "Decaying loss to 0.0001\n",
      "Epoch 11 prediction loss = 0.852\n",
      "Epoch 12 prediction loss = 0.852\n",
      "Epoch 13 prediction loss = 0.852\n",
      "Epoch 14 prediction loss = 0.852\n",
      "Epoch 15 prediction loss = 0.852\n",
      "Epoch 16 prediction loss = 0.852\n",
      "Decaying loss to 1e-05\n",
      "Epoch 17 prediction loss = 0.851\n",
      "Epoch 18 prediction loss = 0.851\n",
      "Epoch 19 prediction loss = 0.850\n",
      "Epoch 20 prediction loss = 0.851\n",
      "Epoch 21 prediction loss = 0.851\n",
      "Epoch 22 prediction loss = 0.850\n",
      "Decaying loss to 1.0000000000000002e-06\n",
      "Epoch 23 prediction loss = 0.851\n"
     ]
    }
   ],
   "source": [
    "times = {}\n",
    "\n",
    "for frac in sorted(indices):\n",
    "    idx, idx_test = indices[frac], indices_test[frac]\n",
    "    \n",
    "    start = time()\n",
    "    \n",
    "    sciPENN = sciPENN_API([adata_gene[idx]], [adata_protein[idx]], adata_gene_test[idx_test], \n",
    "                        train_batchkeys = ['donor'], test_batchkey = 'sample')\n",
    "\n",
    "    sciPENN.train(n_epochs = 10000, ES_max = 12, decay_max = 6, \n",
    "                 decay_step = 0.1, lr = 10**(-3), weights_dir = \"tmp\", load = False)\n",
    "    \n",
    "    imputed_test = sciPENN.predict()\n",
    "    \n",
    "    times[frac] = time() - start\n",
    "                                                                                 \n",
    "shutil.rmtree(\"tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in times:\n",
    "    times[key] = [times[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(times, index = ['sciPENN']).T.to_csv(join(base, \"scipenn.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sciPENN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>76.619142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>139.741037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>279.383748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>352.099309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>585.513345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>664.257289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sciPENN\n",
       "0.1   76.619142\n",
       "0.2  139.741037\n",
       "0.4  279.383748\n",
       "0.5  352.099309\n",
       "0.8  585.513345\n",
       "1.0  664.257289"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(join(base, \"scipenn.csv\"), index_col = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“scipen”",
   "language": "python",
   "name": "scipen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
